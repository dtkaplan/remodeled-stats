---
title: "Statistical inference: Is there a discernible pattern?"
description: |
  The method of regression is always capable of finding a pattern in a given data set. But is the pattern it finds genuinely discernible or is it an illusion of accidental alignment? [The image is astronomer Percival Lowell's drawing of the canals of Mars, as he observed in the 1890s using telescopes (but before the advent of astronomical photography).]
author:
  - name: Daniel Kaplan
    url: https://dtkaplan.github.io
date: 01-19-2020
output:
  distill::distill_article:
    self_contained: false
preview: Solomon_Valley_Democrat_Thu__Oct_27__1898_.jpg
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(mosaic)
library(ggformula)
library(mosaicData)
library(LittleApp2)
nbirths <- 50
set.seed(101)
Birth_counts <- Births2015 %>%
  sample_n(size = nbirths)
```

```{r echo=FALSE}
gf_jitter(births ~ wday,  data = Birth_counts, 
          height = 0, alpha = 0.5, width = 0.1) 
```



## Constellations, fog, and discerning reality

## Will my result be reproducible?

## Quantifying discernibility



5. Is there something about this graphic that *explains* the bi-modality we saw in the previous graphics?

[More discussion. Seem obvious that weekends are different from weekday. Less obvious that Sunday and Saturday are different, or that the individual working weekdays are different from one another.]

Let's compare Monday through Friday. Here's the graph, redrawn to exclude the weekends.

```{r echo=FALSE}
Weekdays <- Birth_counts %>%
  filter( ! wday %in% c("Sat", "Sun")) 
gf_jitter(births ~ wday,  data = Weekdays, 
          height = 0, alpha = 0.5, width = 0.1)  

```

6. What do you think: are the weekdays different from one another?

[Discussion. What if the outlier on Friday had happened on  Thursday, etc.]

Reasonable people can disagree about whether there is a day-to-day pattern in the data. Is seeing differences like seeing animal shapes in clouds. (Hint: Clouds aren't really animals!) Or is there something we can put our finger on. Said another way: How would you and a person with the opposite opinion try to convince one another? What would cause  you to give up your opinion?

Many tasks in statistics are about not having to rely entirely on personal judgement about whether there is a real pattern. The techniques by which  these tasks are accomplished have been worked out over the last century, and are used almost universally in science, commerce, government and any other setting where data is used to draw conclusions. 

We're going to work through one of the most widely used such techniques, explaining it with reference  to  a  graphic rather than with mathematical algorithms. (We can leave it  to the computer to carry out the algorithm precisely, but you'll see that you get more or less the same answer just by looking at the graph.)

Here are the steps.

**Step 1**. On the graph, draw a mathematical function that takes day-of-week as the input and puts out a single number which is representative of the data for that day of the week.

```{r echo=FALSE}
# mod <- lm(births ~ wday, data = Weekdays)
# res <- make_model_plots(births ~ wday, data = Weekdays)
# res$P1
```

Question:  You might disagree about the precise position of the bars showing the function output for each day. What would you  look for in a "good" position? It happens that statistics has techniques for deciding where to draw the bars that, like the overall method, are universally used.

**Step 2**. Measure how much variation  in the response variable there is.

[This is where we introduce summary intervals and variance.]

**Step 3**. Imagine that each of the actual values in the response variable was replaced by the corresponding model value.  That is, imagine what a graph of blue dots would look like if each black dot were  moved horizontally down to  the  corresponding function output value.  [An effective way to show this is with one of the StatPREP Little Apps: [here](https://dtkaplan.shinyapps.io/LA_linear_regression/)]. Measure how much variation there is among the blue dots.

The result of Step 3 is the amount of variation that's *explained* by the model.

In understanding Steps 2 and 3, it can help to make a graph on  the side, showing the vertical spread of the response variable and of the model values, like this:

```{r echo=FALSE}
# gridExtra::grid.arrange(res$P1, res$P2$P,
#                                nrow = 1, 
#                                widths = c(3, 1))
```

[Discussion about the blue dots, the meaning of the bars shown in the right graphic, how to calculate the variance, etc.]

**Step 4**. Now to do some calculations. The quantity we are going to calculate is called F, named after its inventor, Ronald Fisher. He invented it in 1925, an invention that marked the start of the pre-computer modern era in statistics.

We have some numbers:

- $n=$`r nbirths`
- Variance of the response variable: $v_r$ = `fr round(var(Weekdays$births), -3)`
- Variance of the model values: $v_m$ = `fr round(var(fitted(mod)), -3)`

In terms of these numbers, F  is

$$\mbox{F} = \frac{n-5}{4}\frac{v_m}{v_r - v_m}$$
You would be right to wonder where this formula comes from. What are the 4 and the 5 about? Will it always be 4 and 5 or does it depend on something in the specific situation? Why do we use variance instead of its square root. Why  $n-1$ and not  $n$. Why not just use $v_m / v_r$ to simplify things? There  are answers to all  these questions, those will be clearer when we have the concepts to describe precisely what we mean by  a "real"  or an  "accidental" pattern.

Still,  notice that F is bigger:

- When $n$ is bigger. That is, more data gives bigger F.
- When $v_m$ is bigger. That is, a model that explains more of the variation gives bigger F.

Plugging in our numbers here:

$$\mbox{F} = (\frac{50 - 5}{4}) \frac{177000}{398000  - 177000} = 7.8$$

The standard in  science  is that  F > 4 means that you're entitled to claim that the data point to a day-to-day difference in birth numbers.

Why 4? Again, we'll be able to see why 4 was selected as the threshold when we understand precisely what is the difference between a "real" and "accidental" pattern.

**Another example.** [I would interleaf examples stage by stage, leaving the "is the  pattern accidental?" question toward the end.]

There's an urban legend that pregnant women who are older are more likely to have conceived a boy than younger women. [Notice the conditioning in this statement. It's only about pregnant women.] 

`r nbabies <- 1000`

Let's go to the data. We'll use the Centers for Disease Control data on individual births. Here, we have $n=$4,000,000 so we can anticipate that F is likely to  be large. But so  that  you can see the individual dots in the graph, we'll use a sample of  just `r nbabies` births selected at random.  Once you feel comfortable with the idea of a function describing the relationship between the response and explanatory variables, we'll work with larger datasets.

```{r}
set.seed(101)
Babies <- natality2014::Natality_2014_10k %>% 
  sample_n(size = 2*nbabies) %>%
  dplyr::select(mager,  sex, fagecomb) %>%
  mutate(sex = factor(sex)) %>%
  na.omit() %>%
  sample_n(size = nbabies)
gf_point(sex ~ mager,  data = Babies)
```

That's not a very good graph. Let's use jittering and transparency?

```{r echo=FALSE}
gf_jitter(sex ~ mager,  data = Babies,
         height  = 0.1,  width = 0.5, alpha = 0.5) 
```

First ... there's nothing obvious. But let's go through the formalities  of the steps to  find F. [Discussion about how to draw function and what the output should be.]




